# 热点文章计算



![](photo\1.png)



在设计热点文章计算模块时,我采用了两种不同的计算模式。首先是定时计算模式,我使用了XXL-Job的调度中心,通过cron表达式设置每天凌晨2点查询前10天的文章,对文章分值进行加权计算,对每个频道的文章分值进行排序,将前30条保存到Redis中,用于展示在主页。

但是,仅仅依赖定时计算有时无法满足实际需求,比如当天某个文章点击量激增,定时计算就无法及时捕获这种变化。因此,我又设计了基于Kafka Stream的实时流计算热点文章的方案。

在实时计算方案中,我修改了原有的用户点赞、阅读代码,新增了一个Kafka主题。当用户有点赞行为时,作为消费者向该主题发送消息,消息的key为文章id,value为用户行为转换的JSON格式。

然后,我创建了一个Stream处理器作为该主题的消费者,订阅并获取文章的加权分值变化,进行Stream聚合处理。在处理过程中,我使用了Kstream中的时间窗口,对10分钟内获得的消息进行统一聚合,将相同文章id的分值的相同操作进行累加计算,如id为3的文章comment+3、view+10。

该流处理器将处理结果发送至新的消息队列中。数据层监听该消息队列主题,实现了持久化保存点赞数量。最后,我会对当天点赞变化的分数进行加权处理,与缓存中的热点文章进行比较。如果文章已在缓存中,则更新热度值;如果不在缓存中但热度值比缓存中文章高,则将其加入缓存。

通过这种设计,我综合使用了定时计算和实时流计算两种模式,不仅能够满足日常热点文章展示需求,还能实时捕捉文章热度的瞬时变化,提高了系统的灵活性和实时性。

![image-20210621235620854](新热文章-实时计算.assets\image-20210621235620854.png)

